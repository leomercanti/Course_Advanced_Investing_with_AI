{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXMmmDxzwATsL9NNtALZY/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomercanti/Course_Advanced_Investing_with_AI/blob/main/Module_5_Deployment_and_Scaling_of_AI_Driven_Trading_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 5: Deployment and Scaling of AI-Driven Trading Systems**\n",
        "\n",
        "If you havent checked our previous modules yet, you can find them on the links below:\n",
        "- [Module 1](https://colab.research.google.com/drive/15iRO6g-AyE2vGtdodh4xZ5RLmAcPcNV_)\n",
        "- [Module 2](https://colab.research.google.com/drive/1Xr_athUWZH3iKZ6ubzvPnEAN9lPnee-1)\n",
        "- [Module 3](https://colab.research.google.com/drive/1MwPrryj8q-DVMvuBhAOltWF5sdRVaBUq#scrollTo=WOPK7swfVHRb)\n",
        "- [Module 4](https://colab.research.google.com/drive/11_Nihr0VUFQLTK0ZisrPFAJSYmuqdlne#scrollTo=doJgVWJUhdlu)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Learning Goals:**\n",
        "\n",
        "- Learn how to deploy AI-driven trading systems into production environments using cloud platforms like AWS, Google Cloud, or Azure.\n",
        "- Explore containerization techniques using Docker and Kubernetes to ensure scalability and maintainability.\n",
        "- Implement real-time data pipelines for continuous model training and execution of trades.\n",
        "- Understand how to monitor and maintain live trading systems, including performance tracking, error handling, and logging.\n"
      ],
      "metadata": {
        "id": "-C50XmmCrMmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Core Readings and Resources\n",
        "\n",
        "- **Textbook:** \"Machine Learning in Production\" by Sujit Pal\n",
        "  - **Chapter 7:** Model Deployment and Monitoring – Discusses key concepts and best practices for moving AI models into production and how to monitor them effectively.\n",
        "\n",
        "- **Research Papers:**\n",
        "  - “Scaling AI in Financial Services” – This paper explores the challenges and solutions for deploying large-scale AI systems in the financial industry.\n",
        "  - “Real-Time Data Streaming for AI-Driven Trading” – Focuses on the architecture and best practices for setting up real-time data pipelines for live trading.\n",
        "\n",
        "- **Optional:**\n",
        "  - \"Continuous Delivery for Machine Learning\" by Sato et al. – Provides insights into the DevOps practices and tooling for continuous integration, deployment, and delivery of machine learning models."
      ],
      "metadata": {
        "id": "DfLr2uUpruQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Key Topics Overview\n",
        "\n",
        "**Deployment of AI Trading Systems**\n",
        "\n",
        "- **Overview:** Moving your trading system from a local environment to a production environment is a critical step. It involves setting up the infrastructure to handle real-time data, execute trades at scale, and ensure that the system runs smoothly and securely.\n",
        "\n",
        "- **Key Components:**\n",
        "\n",
        "  - **Cloud Platforms:** Use cloud providers like AWS, Google Cloud, or Microsoft Azure to deploy models and trading systems. These platforms offer scalability, reliability, and tools to manage live systems.\n",
        "  - **APIs and Webhooks:** For live trading, APIs (such as Alpaca, Interactive Brokers, or Binance) are essential for executing trades. Webhooks can be used to trigger actions based on market events or model outputs.\n",
        "  - **Latency Considerations:** In financial markets, time is critical. Use low-latency infrastructure, such as colocating servers near exchanges, to ensure rapid trade execution.\n",
        "\n",
        "- **Hands-On Example:** Deploying a Trading Model on AWS Lambda"
      ],
      "metadata": {
        "id": "Cg62jTnNsWF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import yfinance as yf\n",
        "import boto3"
      ],
      "metadata": {
        "id": "4vN0LH03sop-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rVYuYOirHbA"
      },
      "outputs": [],
      "source": [
        "def lambda_handler(event, context):\n",
        "    # Fetch stock data\n",
        "    stock_symbol = event['symbol']\n",
        "    data = yf.download(stock_symbol, period='1d')\n",
        "\n",
        "    # Generate a buy/sell signal (simple example)\n",
        "    latest_close = data['Close'].iloc[-1]\n",
        "    signal = \"buy\" if latest_close < 200 else \"sell\"\n",
        "\n",
        "    # Log the trade signal\n",
        "    client = boto3.client('logs')\n",
        "    log_group = 'trading-signals'\n",
        "    client.create_log_group(logGroupName=log_group)\n",
        "    client.put_log_events(logGroupName=log_group, logStreamName='trade-signals', logEvents=[\n",
        "        {'timestamp': int(time.time() * 1000), 'message': f\"Signal for {stock_symbol}: {signal}\"}\n",
        "    ])\n",
        "\n",
        "    return {\"statusCode\": 200, \"body\": json.dumps(f\"Trade signal: {signal}\")}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Explanation:** This AWS Lambda function fetches stock data using Yahoo Finance, generates a simple buy/sell signal, and logs the trade signal to AWS CloudWatch."
      ],
      "metadata": {
        "id": "C6fV0AgKsx8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Containerization with Docker and Kubernetes**\n",
        "\n",
        "- **Overview:** Containerization ensures that your AI trading system is portable and runs consistently across different environments. Docker enables you to package your entire application, including dependencies, into containers. Kubernetes helps you manage these containers in a scalable way, ensuring high availability and load balancing.\n",
        "\n",
        "- **Key Concepts:**\n",
        "  - **Docker:** Create lightweight containers that encapsulate your trading system. These containers can be easily deployed on cloud platforms or local servers.\n",
        "  - **Kubernetes (K8s):** Orchestrate multiple Docker containers to ensure your trading system is scalable and resilient, even during heavy load or system failures.\n",
        "\n",
        "- **Hands-On Example:** Containerizing a Trading System with Docker"
      ],
      "metadata": {
        "id": "xx6Co6vys1-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 - Dockerfile for Trading System:\n",
        "\n",
        "# Use an official Python runtime as a parent image\n",
        "FROM python:3.9-slim\n",
        "\n",
        "# Set the working directory in the container\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy the current directory contents into the container\n",
        "COPY . /app\n",
        "\n",
        "# Install any needed packages\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Define environment variable\n",
        "ENV NAME TradingSystem\n",
        "\n",
        "# Run the application\n",
        "CMD [\"python\", \"./trading_bot.py\"]"
      ],
      "metadata": {
        "id": "1Ldm1MN7tUcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 - Running a Docker Container\n",
        "\n",
        "# Build the Docker image\n",
        "docker build -t trading-system .\n",
        "\n",
        "# Run the container\n",
        "docker run -d -p 8080:8080 trading-system"
      ],
      "metadata": {
        "id": "u0eJ0eevtcmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Explanation:** The Dockerfile defines a Python-based environment that encapsulates your trading system, including all necessary libraries. The Docker container can now be deployed on any cloud or local infrastructure."
      ],
      "metadata": {
        "id": "aAwMQ2j-uTHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Real-Time Data Pipelines**\n",
        "\n",
        "- **Overview:** A real-time data pipeline is essential for processing streaming market data and making trading decisions on the fly. These pipelines ensure that your trading system reacts to market changes in real time, using technologies like Kafka, Spark, or Flink.\n",
        "\n",
        "- **Key Components:**\n",
        "  - **Data Ingestion:** Collect real-time data from financial APIs or market feeds.\n",
        "  - **Data Processing:** Process the data in real time to generate signals using machine learning models or trading algorithms.\n",
        "  - **Execution:** Automatically place trades based on the generated signals, ensuring minimal delay.\n",
        "\n",
        "- **Hands-On Example:** Building a Real-Time Data Pipeline with Apache Kafka\n",
        "\n",
        "  - **1 - Set up Kafka:** Download and install Kafka from Apache Kafka.\n",
        "\n",
        "  - **2 - Python Kafka Producer and Consumer**"
      ],
      "metadata": {
        "id": "T8cEcVXJuV9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Producer (publishes real-time stock prices)\n",
        "from kafka import KafkaProducer\n",
        "import json\n",
        "import yfinance as yf\n",
        "\n",
        "producer = KafkaProducer(bootstrap_servers='localhost:9092', value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
        "\n",
        "while True:\n",
        "    data = yf.download(\"AAPL\", period='1m')\n",
        "    price = data['Close'].iloc[-1]\n",
        "    producer.send('stock-prices', {'symbol': 'AAPL', 'price': price})\n",
        "    time.sleep(60)"
      ],
      "metadata": {
        "id": "2U00JxLiu4tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consumer (consumes stock prices and makes decisions)\n",
        "from kafka import KafkaConsumer\n",
        "\n",
        "consumer = KafkaConsumer('stock-prices', bootstrap_servers='localhost:9092', value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
        "\n",
        "for message in consumer:\n",
        "    price_data = message.value\n",
        "    print(f\"Received stock price: {price_data['symbol']} at {price_data['price']}\")"
      ],
      "metadata": {
        "id": "sIgJTHBpu8MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Explanation:** The producer sends real-time stock prices to a Kafka topic, and the consumer reads the stock prices to take action (e.g., make trading decisions)."
      ],
      "metadata": {
        "id": "H6VjJjGtu_Nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monitoring and Maintenance**\n",
        "\n",
        "- **Overview:** Once a trading system is deployed, it’s critical to monitor its performance and ensure uptime. Key aspects of monitoring include tracking model performance, latency, errors, and system resource usage. Automated alerting and logging are essential for quickly addressing any issues.\n",
        "\n",
        "- **Tools for Monitoring:**\n",
        "  - **Prometheus and Grafana:** For real-time monitoring and visualization of system metrics.\n",
        "  - **CloudWatch (AWS) or Stackdriver (Google Cloud):** For logging and tracking system performance on cloud platforms.\n",
        "  - **Error Handling and Alerts:** Set up automated alerts for key failure points like API outages, trading errors, or system downtime.\n",
        "\n",
        "- **Hands-On Example:** Monitoring with Prometheus and Grafana\n",
        "\n",
        "  - **1 - Prometheus Metrics Exporter**\n",
        "  - **2 - Set Up Grafana:** Install and configure Grafana to visualize the metrics exported by Prometheus (Optional for this exercise)."
      ],
      "metadata": {
        "id": "T90_p8BfvIgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prometheus_client import start_http_server, Gauge\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Create a Prometheus metric to track stock prices\n",
        "price_gauge = Gauge('stock_price', 'Current price of stock')\n",
        "\n",
        "# Start Prometheus server\n",
        "start_http_server(8000)\n",
        "\n",
        "while True:\n",
        "    # Randomly generate stock price for illustration\n",
        "    price = random.uniform(150, 250)\n",
        "    price_gauge.set(price)\n",
        "    time.sleep(5)"
      ],
      "metadata": {
        "id": "-wnpSqSXvbAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Advanced Concepts: Model Retraining and Continuous Learning\n",
        "\n",
        "**Continuous Model Retraining:**\n",
        "\n",
        "- **Overview:** As market conditions change, AI models need to be updated and retrained to maintain their accuracy. Continuous retraining ensures your models stay up to date with the latest market data.\n",
        "\n",
        "- **Tools:**\n",
        "  - **MLFlow:** Track and manage model versions, data, and hyperparameters for retraining.\n",
        "  - **Airflow:** Schedule and automate the retraining of models at regular intervals.\n",
        "\n",
        "- **Challenges in Scaling AI Trading Systems:**\n",
        "  - **Latency:** Ensuring low-latency performance while scaling.\n",
        "  - **Data Integrity:** Maintaining high-quality, real-time data streams for accurate predictions.\n",
        "  - **Regulatory Compliance:** Ensuring that your trading system complies with financial regulations."
      ],
      "metadata": {
        "id": "6O48Ua09vd8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 End of Module Assignments and Practice (Optional)\n",
        "\n",
        "- **Assignment 1:** Deploy an AI-driven trading system using a cloud platform of your choice. Use Docker and Kubernetes to ensure that your system is scalable and maintainable. Implement real-time data pipelines and backtest the performance on historical data.\n",
        "\n",
        "- **Assignment 2:** Set up monitoring and alerting for your deployed trading system. Use tools like Prometheus and Grafana for real-time metrics and logging. Implement automated error handling and alerts to ensure the system remains operational and performant."
      ],
      "metadata": {
        "id": "-jM0GSCNwDTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the end of this module, you have gained hands-on experience in deploying, scaling, and maintaining AI-driven trading systems. You also have learned how to use cloud infrastructure, containerization, and real-time data pipelines to create robust and scalable trading systems. Additionally, now you understand the importance of monitoring and maintaining your systems in a live trading environment, preparing you for the final steps of deploying and scaling AI-driven solutions in real-world financial markets.\n",
        "\n",
        "This knowledge lays the groundwork for effectively managing and optimizing your AI-driven trading systems as you advance toward mastering AI in investments."
      ],
      "metadata": {
        "id": "ADEsl3-7wOYI"
      }
    }
  ]
}