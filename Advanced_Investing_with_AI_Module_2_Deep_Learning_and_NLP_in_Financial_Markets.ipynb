{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM91tdwJ6WCcw9CXNsLMow6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomercanti/Course_Advanced_Investing_with_AI/blob/main/Advanced_Investing_with_AI_Module_2_Deep_Learning_and_NLP_in_Financial_Markets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Course: Advanced Investing with AI**\n",
        "\n",
        "## Module 2: Deep Learning and NLP in Financial Markets\n",
        "\n",
        "(If you havent checked Module 1 yet, find it [here](https://colab.research.google.com/drive/15iRO6g-AyE2vGtdodh4xZ5RLmAcPcNV_))\n",
        "\n",
        "<br>\n",
        "\n",
        "**Learning Goals:**\n",
        "\n",
        "- Develop a deep understanding of time series modeling using LSTMs and GRUs.\n",
        "- Implement NLP techniques to analyze financial news, social media sentiment, and earnings calls.\n",
        "- Apply deep learning techniques to predict stock prices and market movements.\n",
        "- Use state-of-the-art models like BERT for sentiment analysis in financial contexts.\n"
      ],
      "metadata": {
        "id": "8JvMDctxSrOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Core Readings and Resources\n",
        "\n",
        "- **Textbook:** \"Deep Learning for Finance\" by Patrick Hebron\n",
        "\n",
        "  - Chapter 2: Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) - Provides an in-depth explanation of time series forecasting using deep learning models.\n",
        "\n",
        "- **Research Papers:**\n",
        "\n",
        "  - “Sentiment Analysis of Financial News using Deep Learning” – Focus on how NLP models can be applied to financial texts.\n",
        "  - “Stock Market Prediction using LSTM Networks” – Shows how LSTMs can model complex stock market behaviors.\n",
        "\n",
        "- **Optional:**\n",
        "\n",
        "  - “Attention is All You Need” by Vaswani et al. – Essential paper for understanding the architecture of Transformers, which form the backbone of models like BERT."
      ],
      "metadata": {
        "id": "bgXN5zfGTaLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Key Topics Overview\n",
        "\n",
        "**Time Series Forecasting with LSTMs**\n",
        "\n",
        "- **Why LSTMs?** Traditional neural networks struggle with sequential data, like stock prices, because they don't remember previous inputs. LSTM (Long Short-Term Memory) networks solve this by maintaining a memory state, which makes them well-suited for predicting stock prices based on historical data.\n",
        "\n",
        "- **Main Concepts:**\n",
        "\n",
        "  - Gated Memory Cells: LSTMs use memory gates to retain important information across long sequences of data.\n",
        "  - Vanishing Gradient Problem: LSTMs solve this problem, which traditional RNNs face, allowing them to capture long-term dependencies in financial data.\n",
        "\n",
        "- **Use Case:** Predicting the next day’s stock price using past 30 days of historical prices.\n",
        "\n",
        "- **Hands-On Example:** Predicting Stock Prices Using LSTMs"
      ],
      "metadata": {
        "id": "dSXTIiPwWVt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "ctjcJDdFWv3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download historical data\n",
        "data = yf.download(\"AAPL\", start=\"2016-01-01\", end=\"2024-09-01\")"
      ],
      "metadata": {
        "id": "3JYd9lJMXHJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data (using close price for simplicity)\n",
        "close_prices = data['Close'].values\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(close_prices.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "E7uzwqgmXLOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect data\n",
        "print(data.tail())"
      ],
      "metadata": {
        "id": "gka8m7z5boz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data (using past 60 days to predict the next day)\n",
        "sequence_length = 60\n",
        "X_train, y_train = [], []\n",
        "\n",
        "for i in range(sequence_length, len(scaled_data)):\n",
        "    X_train.append(scaled_data[i-sequence_length:i, 0])\n",
        "    y_train.append(scaled_data[i, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "TEjPcB6fXNkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))  # Predicting next closing price"
      ],
      "metadata": {
        "id": "M-DSOrr3XQuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "zEA0levFXSci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict future prices\n",
        "test_data = scaled_data[-sequence_length:]  # Last 60 days for prediction\n",
        "test_data = np.reshape(test_data, (1, sequence_length, 1))\n",
        "predicted_price = model.predict(test_data)\n",
        "predicted_price = scaler.inverse_transform(predicted_price)\n",
        "\n",
        "print(f\"Predicted next day price: ${predicted_price[0][0]:.2f}\")"
      ],
      "metadata": {
        "id": "0lVRWwcoXUOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLP and Sentiment Analysis in Financial Markets**\n",
        "\n",
        "- **Why NLP in Finance?** Market sentiment derived from news articles, social media, or earnings calls can heavily influence stock price movements. NLP techniques, particularly sentiment analysis, can gauge the mood of the market and provide signals for trading decisions.\n",
        "\n",
        "- **Main Concepts:**\n",
        "\n",
        "  - **Text Preprocessing:** Tokenization, stop-word removal, stemming, and lemmatization.\n",
        "  - **Word Embeddings:** Representing text as vectors using Word2Vec, GloVe, or more advanced models like BERT.\n",
        "  - **Sentiment Analysis:** Using models like BERT, DistilBERT, or simple LSTM networks to classify the sentiment of news articles.\n",
        "\n",
        "- **Hands-On Example:** Sentiment Analysis Using BERT"
      ],
      "metadata": {
        "id": "XEiwAQ_jXiMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch"
      ],
      "metadata": {
        "id": "IOSUfGNpX8Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "id": "vDJzPoHCX_0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example financial headline\n",
        "headline = \"Apple posts record profits, stock soars\""
      ],
      "metadata": {
        "id": "oisN6GrcYBhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "inputs = tokenizer(headline, return_tensors='pt', padding=True, truncation=True, max_length=64)"
      ],
      "metadata": {
        "id": "un9YM7G8YDKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment prediction\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "sentiment = torch.softmax(logits, dim=1).detach().numpy()"
      ],
      "metadata": {
        "id": "9cJQJ8iVYEyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output: sentiment probabilities\n",
        "print(f\"Sentiment probabilities: {sentiment}\")"
      ],
      "metadata": {
        "id": "9t3R5lm1YGeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Sentiment Score Interpretation:** The output is the probability that the news headline is positive or negative. In the context of trading, you can use this sentiment score to make buy/sell decisions.\n",
        "\n",
        "**Applications in Finance:**\n",
        "\n",
        "- **News Sentiment Trading:** Aggregate sentiment from multiple news sources or social media and build sentiment-driven trading algorithms.\n",
        "- **Earnings Call Analysis:** Use NLP to analyze sentiment and key phrases from earnings call transcripts, influencing stock price reactions."
      ],
      "metadata": {
        "id": "PHiK3SdRYM4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Advanced Concepts: Time Series and Transformer Models\n",
        "\n",
        "**Why Transformers in Finance?**\n",
        "Transformers, especially models like BERT, GPT, and RoBERTa, have revolutionized NLP due to their ability to process large amounts of data with attention mechanisms. In finance, they are used for tasks like market sentiment analysis and financial document comprehension.\n",
        "\n",
        "- **Main Concepts:**\n",
        "  - **Attention Mechanism:** The core of transformers that allows the model to focus on different parts of the input text and understand context better.\n",
        "  - **Pre-Trained Models:** Using pre-trained models (like BERT) and fine-tuning them for finance-specific tasks.\n",
        "\n",
        "- **Hands-On Example:** Financial News Classification Using BERT"
      ],
      "metadata": {
        "id": "2wJuyH_lYQLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch"
      ],
      "metadata": {
        "id": "lQJV8pW3Y0kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example dataset: A collection of financial news headlines\n",
        "news_data = [\n",
        "    (\"Apple releases new product line, stock surges\", 1),  # Positive\n",
        "    (\"Tesla faces lawsuits over safety concerns, shares dip\", 0),  # Negative\n",
        "    # Add more headlines...\n",
        "]"
      ],
      "metadata": {
        "id": "im3N1YIIY3ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "texts, labels = zip(*news_data)\n",
        "inputs = tokenizer(list(texts), return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "kekklI6XY6Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader\n",
        "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
        "dataloader = DataLoader(dataset, batch_size=8)"
      ],
      "metadata": {
        "id": "5XhbsS_EY8U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning BERT for classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "ekiZpEsNY-Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop (simplified)\n",
        "for epoch in range(3):\n",
        "    for batch in dataloader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "q_6IJGcvY_9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model inference on new data\n",
        "test_headline = \"Tesla unveils revolutionary battery technology, stock skyrockets\"\n",
        "test_inputs = tokenizer(test_headline, return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
        "output = model(**test_inputs)\n",
        "predicted_sentiment = torch.softmax(output.logits, dim=1).detach().numpy()\n",
        "\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
      ],
      "metadata": {
        "id": "qfvHxlqyZB1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Practical Uses:** Once fine-tuned, you can use BERT to classify any news headline into positive or negative sentiment and integrate it into trading algorithms."
      ],
      "metadata": {
        "id": "XD0vxoOOZKZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 End of Module Assignments and Practice (Optional)\n",
        "\n",
        "- **Assignment 1:** Implement an LSTM model for predicting stock prices using at least 60 days of past price data. Tune the hyperparameters (e.g., number of LSTM units, epochs, and batch size) for optimal performance.\n",
        "\n",
        "- **Assignment 2:** Download financial news articles related to specific stocks and perform sentiment analysis using a pre-trained BERT model. Analyze the sentiment’s correlation with stock price movements."
      ],
      "metadata": {
        "id": "hU8zfnNZZQW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the end of **Module 2**, you should be familiar with using **deep learning models**, such as **LSTMs**, to predict stock prices based on time series data and applying **NLP** techniques like **BERT** for sentiment analysis on financial news and reports. You’ve learned how to extract insights from both structured time series data and unstructured text data, which are critical for making more informed investment decisions.\n",
        "\n",
        "This knowledge sets the stage for even more advanced AI techniques, including **reinforcement learning** and **automated trading**, which you will explore in the next module."
      ],
      "metadata": {
        "id": "AAMz6c4lag4-"
      }
    }
  ]
}